# AI 코드 생성기의 데이터 포이즈닝 공격 대응을 위한 데이터 전처리 파이프라인 설계 
### (A Defensive Data Preprocessing Pipeline for Mitigating Data Poisoning in AI Code Generators)

## 요약

 최근 대규모 언어모델(LLM)을 기반으로 하는 AI 코드 생성기가 널리 활용되면서, 학습 데이터에 악의적인 코드가 삽입되어 취약한 코드를 생성하도록 유도하는 데이터 포이즈닝 공격 사례가 증가하고 있다. 기존 연구들은 주로 출력 검증, 사후 필터링과 같은 모델 학습 단계 이후의 방어 기법에 초점을 맞추고 있으며, 학습 데이터 수준에서의 사전적 방어 연구는 제한적이다. 결과적으로 데이터 오염이 모델 내부 표현에 직접 영향이 미치는 문제가 지속되는 문제점이 존재한다. 따라서, 본 연구에서는 AI 코드 생성기의 데이터 포이즈닝 공격에 대응하는 방어형 데이터 전처리 파이프라인을 설계하였다. 사전 학습된 코드 언어 모델을 활용해 각 데이터의 이상치와 일관성 점수를 측정한다. 이후 CVSS 점수와 통합하여 최종 위험도를 산정해 고위험 데이터를 자동 식별 및 제거함으로써 학습 데이터의 신뢰도를 향상시킨다. 파이프라인 적용 전후의 취약성을 평가하기 위해 공개된 AI 모델 생성 코드 데이터를 활용해 CodeT5+ 모델을 학습했다. 그 결과 파이프라인 적용 후 모델의 공격 성공률(ASR)이 기존에 비해 약 75% 감소하였다. 이는 제안하는 전처리 파이프라인이 AI 코드 생성기의 데이터 포이즈닝 공격에 대한 방어 효과를 가지며, 데이터 중심 방어 전략의 실질적인 가능성을 보여준다.

## 파이프라인 구조

<img width="2879" height="1206" alt="image" src="https://github.com/user-attachments/assets/99b0455f-2218-4b3f-b946-a4d942a78d5c" />


## 실험 결과
